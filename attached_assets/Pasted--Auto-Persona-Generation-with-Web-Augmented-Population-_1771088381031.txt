# Auto-Persona Generation with Web-Augmented Population Research

**Date:** February 2026
**Status:** Implementation-Ready Proposal

---

## 1. Problem Statement

Creating personas for interview simulations is entirely manual. Each persona has 14+ fields. A representative simulation set requires 5-10 personas — 70-140 fields of manual data entry that requires research domain expertise to do well.

This produces three outcomes:
1. **Setup friction** — 30-60 minutes of persona creation before a single simulation can run
2. **Shallow personas** — under time pressure, researchers default to stereotypical archetypes
3. **Low coverage** — most projects end up with 3-4 personas instead of the 5-10 needed for diversity

### What Changes

Auto-persona generation uses a GPT-5 reasoning model with web search to:
- Research the target population using real demographic data, behavioral studies, and domain-specific reports
- Synthesize representative personas grounded in that research
- Produce fully-formed persona objects ready for simulation

The researcher provides a prompt describing who they want to interview, optionally uploads supporting documents, and reviews the generated personas before saving.

---

## 2. Input Design

### 2.1 Research Prompt (Required)

Free-form text area. The researcher describes their target population and research context.

**Examples:**
- *"Urban millennials (25-35) in Southeast Asia who use ride-hailing apps daily for commuting. Mix of white-collar workers and gig economy participants."*
- *"UK NHS patients aged 40-75 experiencing waiting times for specialist referrals, across different socioeconomic backgrounds, urban and rural."*
- *"First-generation college students in the US navigating financial aid processes. Need perspectives from different ethnic backgrounds, family income levels, and geographic regions."*

**Validation:** min 20 characters, max 2,000 characters.

### 2.2 Project Context Auto-Fill

The system automatically injects existing project metadata into the research phase:

| Field | Source | Purpose |
|-------|--------|---------|
| `objective` | `projects.objective` | Aligns personas to research goals |
| `audienceContext` | `projects.audience_context` | Grounds personas in known target audience |
| `strategicContext` | `projects.strategic_context` | Focuses personas on strategic questions |
| `contextType` | `projects.context_type` | Adjusts persona framing (product, marketing, CX, content) |
| `avoidRules` | `projects.avoid_rules` | Carries topic restrictions into `topicsToAvoid` |

If a project has minimal metadata, the dialog surfaces a warning (matching `GenerateTemplateDialog`'s pattern at line 186) and proceeds with the research prompt alone.

### 2.3 Document Upload

A secondary input for uploading supporting data — survey exports, screening criteria, demographic tables, research briefs.

**Supported formats:**
- **CSV** — parsed into structured rows, first 200 rows included as context
- **Plain text / Markdown** — included verbatim
- **PDF** — text extracted, first 20 pages

**Limits:** max 1 file, max 2MB. Parsed content is truncated at 8,000 tokens before injection into the research prompt.

**Implementation:** The Responses API natively supports file inputs via `input_file` — PDFs and text files can be passed directly without a separate parsing library. CSV files need minimal preprocessing (read and format as markdown table).

### 2.4 Configuration

| Setting | Options | Default | Notes |
|---------|---------|---------|-------|
| Persona count | 3-10 | 5 | Aligns with `SIMULATION_LIMITS.MAX_PERSONAS_PER_RUN` |
| Edge case personas | Toggle | Off | Includes 1-2 outlier personas (extreme skeptic, expert with atypical views) |
| Diversity mode | `balanced` / `maximize` | `balanced` | `maximize` forces maximum spread across attitude, verbosity, domain knowledge |

---

## 3. Web Research Phase (Always On)

### 3.1 Approach: OpenAI Responses API with `web_search` Tool

Every generation includes web research. The model uses OpenAI's Responses API with the built-in `web_search` tool to research the target population before generating personas.

**Why the Responses API:**
- **Single vendor** — Alvia already uses OpenAI for all LLM workloads. No new API keys or billing.
- **Model-directed search** — the model decides what to search based on the research prompt. No need to engineer search queries.
- **Inline citations** — the Responses API returns `url_citation` annotations with source URLs and titles, carried through to the review UI.
- **Native file input** — PDF and text documents can be passed directly via `input_file`, eliminating the need for separate parsing libraries.
- **Reasoning token tracking** — the API reports `reasoning_tokens` in `completion_tokens_details`, which integrates with our existing usage tracking.

### 3.2 What the System Searches For

The model is instructed to research:

1. **Demographic distributions** — age, gender, income, education, geographic spread for the target population
2. **Behavioral patterns** — usage habits, decision-making factors, adoption curves
3. **Communication norms** — formality levels, directness, cultural communication styles
4. **Domain knowledge levels** — what the population typically knows vs. doesn't
5. **Biases and sensitivities** — common preconceptions, pain points, trust factors

### 3.3 Fallback Strategy

Web search is always attempted but may not always succeed. The system degrades gracefully:

| Scenario | Detection | Behavior |
|----------|-----------|----------|
| No useful results | Model self-reports low confidence | Generate from prompt + project context only; flag as "ungrounded" in UI |
| Partial results | Some dimensions have citations, others don't | Use available research; fill gaps from prompt; indicate which dimensions are research-backed |
| API rate limit or timeout | HTTP error | Retry once after 5s; if still failing, proceed without web search; surface warning |
| Responses API unavailable | Connection failure | Surface error to user; do not silently fall back to a lesser model |

The population brief always includes a `confidence` field (`high` / `medium` / `low`) so the researcher can assess how well-grounded the results are.

---

## 4. Two-Phase Generation Architecture

### Why Two Phases

Separating research from synthesis provides:

1. **Reusability** — the population brief is independently valuable. Regenerating personas (Phase 2) doesn't re-run expensive web research (Phase 1).
2. **Debuggability** — when a persona looks wrong, inspect the brief to determine if the issue is research or synthesis.
3. **Cost control** — Phase 1 (web search + heavy reasoning) is the expensive call. Phase 2 (structured generation) is cheap. Phase 2 re-runs are nearly free.

### Phase 1: Population Research

| Property | Value |
|----------|-------|
| **Duration** | ~20-40 seconds |
| **API** | OpenAI Responses API |
| **Model** | `gpt-5` with `reasoning_effort: "high"` |
| **Tools** | `web_search` (built-in) |
| **Input** | Research prompt + project context + uploaded document (if any) |
| **Output** | Structured population brief with inline citations |
| **LLM use case** | `barbara_persona_research` |
| **Output format** | `text.format: { type: "json_schema", ... }` |

**Population brief schema:**

```typescript
interface PopulationBrief {
  targetPopulation: string;
  confidence: "high" | "medium" | "low";
  demographics: {
    summary: string;
    distributions: Array<{
      dimension: string;
      breakdown: string;
      source?: string;
    }>;
  };
  behavioralPatterns: Array<{
    pattern: string;
    prevalence: string;
    source?: string;
  }>;
  communicationNorms: Array<{
    norm: string;
    context: string;
  }>;
  domainKnowledgeLevels: Array<{
    segment: string;
    level: "none" | "basic" | "intermediate" | "expert";
    description: string;
  }>;
  biasesAndSensitivities: Array<{
    topic: string;
    nature: string;
    source?: string;
  }>;
  suggestedPersonaProfiles: Array<{
    archetype: string;
    rationale: string;
    representsPct: string;
  }>;
  sources: Array<{
    url: string;
    title: string;
    relevance: string;
  }>;
}
```

### Phase 2: Persona Synthesis

| Property | Value |
|----------|-------|
| **Duration** | ~10-20 seconds |
| **API** | OpenAI Responses API |
| **Model** | `gpt-5` with `reasoning_effort: "medium"` |
| **Tools** | None |
| **Input** | Population brief + persona count + diversity mode + edge case toggle |
| **Output** | Array of persona objects matching `InsertPersona` schema |
| **LLM use case** | `barbara_persona_generation` |
| **Output format** | `text.format: { type: "json_schema", ... }` |

### Population Brief Persistence

Briefs are persisted so Phase 2 can be re-run without re-running Phase 1.

**New table: `population_briefs`**

```typescript
export const populationBriefs = pgTable("population_briefs", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  projectId: varchar("project_id").notNull()
    .references(() => projects.id, { onDelete: "cascade" }),
  researchPrompt: text("research_prompt").notNull(),
  additionalContext: text("additional_context"),
  brief: jsonb("brief").notNull(),         // PopulationBrief JSON
  confidence: text("confidence").notNull(), // "high" | "medium" | "low"
  createdAt: timestamp("created_at").defaultNow(),
}, (table) => [
  index("idx_population_brief_project").on(table.projectId),
]);
```

---

## 5. Diversity & Quality Controls

### Systematic Enum Distribution

The synthesis prompt enforces distribution across the three behavioral enums:

| Mode | Strategy |
|------|----------|
| `balanced` | At least 2 distinct values per enum; no single value used more than 40% of the time |
| `maximize` | Every persona gets a unique (attitude, verbosity, domainKnowledge) combination; with 5+ personas, at least 3 distinct values per enum |

### Anti-Stereotyping Prompt (included in Phase 2 system prompt)

```
DIVERSITY RULES:
1. Do NOT assign personality traits based on demographic stereotypes (e.g., do not
   make all young people "tech-savvy" or all older people "resistant to change").
2. Vary occupation and education independently of age and gender.
3. Assign "reluctant" or "evasive" attitudes to demographically diverse personas —
   not only to older or less educated segments.
4. Background stories should reflect individual circumstances, not demographic
   generalizations.
5. Ensure at least one persona contradicts the "expected" profile for their
   demographic segment (e.g., a senior citizen who is an early adopter, or a
   tech worker with low domain knowledge in their own field).
```

### Post-Generation Validation

After Phase 2, the backend validates the generated set:

1. **Enum coverage** — minimum distinct values per behavioral enum based on diversity mode
2. **Demographic spread** — age ranges, genders, and locations are not monolithic
3. **Name uniqueness** — no duplicate names
4. **Trait variety** — no two personas share more than 50% of their traits array

If validation fails, Phase 2 is re-run once with an appended correction prompt specifying which dimensions need more variation.

### Citation Handling

Citations from Phase 1 are stored in the population brief's `sources` array and surfaced in the review UI. They are supplementary context for researcher verification — not a quality guarantee. Per-persona source attribution is not tracked in V1 (too unreliable at the individual field level).

---

## 6. UX Flow

### Entry Point

"Generate Personas with AI" button with `Sparkles` icon in the project's persona management area, alongside the existing "Add Persona" button.

### Dialog States

```
┌─────────────────────────────────────────────┐
│  State 1: INPUT                             │
│  ┌───────────────────────────────────────┐  │
│  │ Research Prompt (text area)           │  │
│  │ "Describe your target population..." │  │
│  └───────────────────────────────────────┘  │
│  ┌───────────────────────────────────────┐  │
│  │ Upload document (optional)            │  │
│  │ [Choose file] CSV, PDF, or TXT       │  │
│  └───────────────────────────────────────┘  │
│  Persona count: [5 ▼]  Edge cases: [○]     │
│  Diversity: [balanced ▼]                    │
│                                             │
│  (!) Limited project context (if applicable)│
│                                             │
│  [Cancel]                      [Generate]   │
└─────────────────────────────────────────────┘

┌─────────────────────────────────────────────┐
│  State 2: GENERATING                        │
│  ┌───────────────────────────────────────┐  │
│  │ ✓ Phase 1: Researching population     │  │
│  │   Searched 6 sources, confidence: high│  │
│  │                                       │  │
│  │ ● Phase 2: Generating 5 personas...   │  │
│  │   ████████░░░░░░░░░░                  │  │
│  └───────────────────────────────────────┘  │
│                                             │
│  [Cancel]                                   │
└─────────────────────────────────────────────┘

┌─────────────────────────────────────────────┐
│  State 3: REVIEW                            │
│  ┌───────────────────────────────────────┐  │
│  │ ▸ Population Brief (expandable)       │  │
│  │   8 sources, confidence: high         │  │
│  └───────────────────────────────────────┘  │
│  ┌───────────────────────────────────────┐  │
│  │ Persona Cards (scrollable grid)       │  │
│  │ ┌─────────────────────────────────┐   │  │
│  │ │ Maria Chen, 28                  │   │  │
│  │ │ Product Manager · Singapore     │   │  │
│  │ │ cooperative · high · intermediate│   │  │
│  │ │ "Detail-oriented, pragmatic"    │   │  │
│  │ │                      [Remove]   │   │  │
│  │ └─────────────────────────────────┘   │  │
│  │ ┌─────────────────────────────────┐   │  │
│  │ │ Ravi Krishnan, 34               │   │  │
│  │ │ Gig driver · Chennai            │   │  │
│  │ │ reluctant · low · basic         │   │  │
│  │ │ ...                             │   │  │
│  │ └─────────────────────────────────┘   │  │
│  └───────────────────────────────────────┘  │
│                                             │
│  [Regenerate ↻]  [Cancel]  [Save 5 Personas]│
└─────────────────────────────────────────────┘
```

### Async Pattern: Two Sequential Mutations

The client makes two sequential HTTP requests — one per phase. This gives real phase progress without polling infrastructure.

```
Client                          Server
  │                               │
  ├─ POST .../personas/research ──►│ Phase 1: Responses API + web_search
  │        (waits ~20-40s)        │ Returns PopulationBrief
  │◄── { briefId, brief } ────────│
  │                               │
  │  (UI updates: "Phase 1 done") │
  │                               │
  ├─ POST .../personas/synthesize─►│ Phase 2: Responses API, json_schema
  │        (waits ~10-20s)        │ Returns persona array
  │◄── { personas[] } ────────────│
  │                               │
  │  (UI updates: show review)    │
```

The "Regenerate" button re-calls only the synthesize endpoint with the existing `briefId`, skipping Phase 1.

### Review Actions

| Action | Behavior |
|--------|----------|
| **Remove persona** | Client-side removal before saving |
| **Regenerate** | Re-runs Phase 2 only with existing population brief |
| **Cancel** | Discards everything |
| **Save N Personas** | Batch-creates via `POST /api/projects/:projectId/personas` (one per persona, same as manual creation) |

---

## 7. Suggested Prompts

### Phase 1: Population Research System Prompt

```
You are a research population analyst. Your task is to research a target population
for a qualitative interview study and produce a structured population brief.

TASK:
Given the research context below, use web search to find real demographic data,
behavioral research, and domain-specific studies about this population. Search for
at least 3-5 different aspects of the population.

SEARCH STRATEGY:
- Search for demographic breakdowns (census data, industry reports, market sizing)
- Search for behavioral patterns (adoption studies, satisfaction surveys, usage data)
- Search for communication and cultural norms relevant to this population
- Search for domain knowledge distributions (professional qualifications, experience levels)
- Search for known biases, pain points, or sensitive topics in this population

CONFIDENCE ASSESSMENT:
After your research, assess your confidence level:
- "high": Found multiple credible sources with specific data for this population
- "medium": Found some relevant data but had to generalize from adjacent populations
- "low": Found little to no specific data; brief is primarily based on general knowledge

SUGGESTED PERSONA PROFILES:
Based on your research, suggest 3-8 distinct persona archetypes that would
represent the key segments of this population. For each, explain:
- What archetype they represent (e.g., "Early adopter professional", "Reluctant
  traditionalist")
- Why this archetype matters for the research (what perspective they bring)
- Roughly what percentage of the target population they represent

OUTPUT FORMAT:
Return a JSON object matching the PopulationBrief schema. Every claim should
include a source URL where possible. Do not fabricate sources — if you cannot
find data for a dimension, omit the source field and note this in your
confidence assessment.
```

### Phase 1: User Prompt Template

```
RESEARCH CONTEXT:
{researchPrompt}

PROJECT CONTEXT:
Project: {projectName}
{objective ? `Research Objectives: ${objective}` : ""}
{audienceContext ? `Target Audience: ${audienceContext}` : ""}
{contextType ? `Context Type: ${contextType}` : ""}
{strategicContext ? `Strategic Context: ${strategicContext}` : ""}
{avoidRules ? `Topics/Rules to Avoid: ${avoidRules}` : ""}

{additionalContext ? `ADDITIONAL CONTEXT PROVIDED BY RESEARCHER:\n${additionalContext}` : ""}

Research this population thoroughly using web search. Produce a structured
population brief with citations.
```

### Phase 2: Persona Synthesis System Prompt

```
You are an expert persona designer for qualitative research simulations. Your task
is to generate realistic, diverse interview personas grounded in population research.

INPUT:
You will receive a population brief containing demographic distributions, behavioral
patterns, communication norms, domain knowledge levels, and biases/sensitivities
for a target population. You will also receive configuration settings.

PERSONA SCHEMA:
Each persona MUST include ALL of the following fields:

{
  "name": "string — realistic full name appropriate to the persona's demographics and location",
  "description": "string — 1-2 sentence summary of who this person is (max 500 chars)",
  "ageRange": "string — specific range, e.g. '25-34', '45-54', '65+'",
  "gender": "string — e.g. 'Female', 'Male', 'Non-binary'",
  "occupation": "string — specific job title, not generic (max 100 chars)",
  "location": "string — city or region, specific enough to be meaningful (max 100 chars)",
  "attitude": "MUST be one of: cooperative, reluctant, neutral, evasive, enthusiastic",
  "verbosity": "MUST be one of: low, medium, high",
  "domainKnowledge": "MUST be one of: none, basic, intermediate, expert",
  "traits": ["array of 3-5 personality traits as strings"],
  "communicationStyle": "string — how this persona expresses themselves (max 500 chars)",
  "backgroundStory": "string — 2-4 sentence backstory grounding this persona in reality (max 2000 chars)",
  "topicsToAvoid": ["array of 0-3 sensitive topics this persona deflects on"],
  "biases": ["array of 1-3 preconceptions or strong opinions this persona holds"]
}

GROUNDING RULES:
1. Every persona's demographics (age, occupation, location) MUST be drawn from
   the population brief's demographic data. Do not invent demographics unsupported
   by the research.
2. If the research did not find data for a specific dimension, use reasonable
   defaults consistent with the research prompt and note this.
3. Names must be culturally appropriate for the persona's stated location and
   cultural background.
4. Background stories must reflect individual circumstances, not demographic
   generalizations.

DIVERSITY RULES:
1. Do NOT assign personality traits based on demographic stereotypes (e.g., do not
   make all young people "tech-savvy" or all older people "resistant to change").
2. Vary occupation and education independently of age and gender.
3. Assign "reluctant" or "evasive" attitudes to demographically diverse personas —
   not only to older or less educated segments.
4. Background stories should reflect individual circumstances, not demographic
   generalizations.
5. Ensure at least one persona contradicts the "expected" profile for their
   demographic segment.

ENUM DISTRIBUTION ({diversityMode} mode):
{diversityMode === "balanced" ?
  "- Use at least 2 distinct values for attitude, verbosity, and domainKnowledge\n- No single enum value should appear on more than 40% of personas"
  :
  "- Every persona must have a unique (attitude, verbosity, domainKnowledge) combination\n- Use at least 3 distinct values for each enum if generating 5+ personas"
}

{edgeCases ?
  "EDGE CASES: Include 1-2 outlier personas — people who are atypical for this population but still realistic. Examples: an extreme skeptic, a domain expert with unconventional views, someone from an unexpected demographic segment."
  : ""
}

OUTPUT:
Return a JSON object with a single key "personas" containing an array of exactly
{personaCount} persona objects matching the schema above.
```

### Phase 2: User Prompt Template

```
POPULATION BRIEF:
{JSON.stringify(populationBrief, null, 2)}

CONFIGURATION:
- Generate exactly {personaCount} personas
- Diversity mode: {diversityMode}
- Edge case personas: {edgeCases ? "Yes — include 1-2 outlier personas" : "No"}

Generate {personaCount} diverse, research-grounded personas for this population.
```

### Diversity Validation Retry Prompt (appended to Phase 2 if validation fails)

```
CORRECTION REQUIRED:
The previous generation failed diversity validation. Specific issues:
{validationErrors.join("\n")}

Regenerate the persona set, ensuring:
- Each issue listed above is addressed
- All other requirements from the original prompt still apply
- Do not simply swap values randomly — maintain realistic persona coherence
```

---

## 8. Token Counting Integration

### New Usage Extractor for Responses API

The existing `extractOpenAIChatUsage` function parses `response.usage` from the Chat Completions API. The Responses API returns a similar but enhanced structure including `reasoning_tokens`. A new extractor function handles this:

```typescript
// In server/llm-usage.ts

export function extractOpenAIResponsesUsage(
  response: {
    usage?: {
      prompt_tokens?: number;
      completion_tokens?: number;
      total_tokens?: number;
      prompt_tokens_details?: { cached_tokens?: number };
      completion_tokens_details?: { reasoning_tokens?: number };
    } | null;
  },
  model: string,
): { usage: NormalizedTokenUsage; status: LLMUsageStatus } {
  if (!response.usage) {
    return {
      usage: {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
        inputAudioTokens: 0,
        outputAudioTokens: 0,
      },
      status: "missing_usage",
    };
  }
  const u = response.usage;
  return {
    usage: {
      promptTokens: u.prompt_tokens ?? 0,
      completionTokens: u.completion_tokens ?? 0,
      totalTokens: u.total_tokens ?? (u.prompt_tokens ?? 0) + (u.completion_tokens ?? 0),
      inputAudioTokens: 0,
      outputAudioTokens: 0,
      inputCachedTokens: u.prompt_tokens_details?.cached_tokens ?? 0,
    },
    status: "success",
  };
}

export function makeResponsesUsageExtractor(model: string) {
  return (response: any) => {
    const { usage, status } = extractOpenAIResponsesUsage(response, model);
    return { usage, status, rawUsage: response?.usage ?? null };
  };
}
```

The `rawUsage` field preserves the full API response (including `reasoning_tokens`) in the `llmUsageEvents` table for detailed cost analysis. The `inputCachedTokens` field on `NormalizedTokenUsage` already exists and maps to `prompt_tokens_details.cached_tokens`.

### New LLM Use Cases

Add two entries to `LLM_USE_CASES` in `shared/types/llm-usage.ts`:

```typescript
export const LLM_USE_CASES = [
  // ... existing 19 entries ...
  "barbara_persona_research",     // Phase 1: web research + population brief
  "barbara_persona_generation",   // Phase 2: persona synthesis from brief
] as const;
```

### Usage Tracking in Phase 1

```typescript
const tracked = await withTrackedLlmCall({
  attribution: { workspaceId, projectId },
  provider: "openai",
  model: config.model,  // "gpt-5"
  useCase: "barbara_persona_research",
  timeoutMs: 90_000,
  callFn: async (signal) => {
    return await openai.responses.create({
      model: config.model,
      input: [
        { role: "system", content: researchSystemPrompt },
        { role: "user", content: researchUserPrompt },
      ],
      tools: [{ type: "web_search" }],
      text: {
        format: {
          type: "json_schema",
          name: "population_brief",
          strict: true,
          schema: populationBriefJsonSchema,
        },
      },
      reasoning: { effort: "high" },
    });
  },
  extractUsage: makeResponsesUsageExtractor(config.model),
});

// Access the result
const briefText = tracked.result.output_text;
const citations = tracked.result.output
  .filter((item: any) => item.type === "message")
  .flatMap((item: any) => item.content)
  .flatMap((content: any) => content.annotations ?? [])
  .filter((a: any) => a.type === "url_citation");
```

### Usage Tracking in Phase 2

```typescript
const tracked = await withTrackedLlmCall({
  attribution: { workspaceId, projectId },
  provider: "openai",
  model: config.model,  // "gpt-5"
  useCase: "barbara_persona_generation",
  timeoutMs: 60_000,
  callFn: async (signal) => {
    return await openai.responses.create({
      model: config.model,
      input: [
        { role: "system", content: synthesisSystemPrompt },
        { role: "user", content: synthesisUserPrompt },
      ],
      text: {
        format: {
          type: "json_schema",
          name: "generated_personas",
          strict: true,
          schema: generatedPersonasJsonSchema,
        },
      },
      reasoning: { effort: "medium" },
    });
  },
  extractUsage: makeResponsesUsageExtractor(config.model),
});

const personas = JSON.parse(tracked.result.output_text).personas;
```

### Barbara Config Extension

Add two new entries to `BarbaraConfig` and the default config:

```typescript
// In BarbaraConfig interface:
personaResearch: BarbaraUseCaseConfig;
personaGeneration: BarbaraUseCaseConfig;

// Default values:
personaResearch: {
  model: "gpt-5",
  verbosity: "medium",
  reasoningEffort: "high",     // Heavy thinking for research quality
},
personaGeneration: {
  model: "gpt-5",
  verbosity: "low",
  reasoningEffort: "medium",   // Moderate reasoning for synthesis
},
```

Note: `reasoningEffort` maps to the Responses API's `reasoning.effort` parameter. The `verbosity` field is not used by the Responses API but is kept for config consistency.

---

## 9. Technical Architecture

### New Module: `server/persona-generation/`

```
server/persona-generation/
├── index.ts          # Re-exports (~10 lines)
├── types.ts          # PopulationBrief, GenerationConfig, JSON schemas (~120 lines)
├── research.ts       # Phase 1: population research via Responses API (~180 lines)
├── synthesis.ts      # Phase 2: persona generation from brief (~200 lines)
└── validation.ts     # Post-generation diversity validation (~100 lines)
```

All files stay under the 500-line limit. `barbara-orchestrator.ts` is not touched (per CLAUDE.md watch list constraint — must only shrink).

### New Route File: `server/routes/persona-generation.routes.ts` (~120 lines)

```typescript
// POST /api/projects/:projectId/personas/research
//   Body: { researchPrompt: string, additionalContext?: string, uploadedFile?: base64 }
//   Response: { briefId: string, brief: PopulationBrief }

// POST /api/projects/:projectId/personas/synthesize
//   Body: { briefId: string, personaCount: number, diversityMode: string, edgeCases: boolean }
//   Response: { personas: GeneratedPersonaWithMeta[] }
```

Both endpoints require authentication and `verifyUserAccessToProject`.

### New Frontend Component: `client/src/components/simulation/GeneratePersonasDialog.tsx` (~350 lines)

Three-state dialog following `GenerateTemplateDialog` patterns:
- Two sequential `useMutation` hooks (research, synthesize)
- File upload via standard `<input type="file">`
- Persona cards reuse layout from `PersonaCard.tsx`
- React Query invalidation on save

### Database Changes

1. **New table:** `population_briefs` (defined in Section 4)
2. **New storage methods** in `server/storage/simulation.ts`:
   - `createPopulationBrief(data: InsertPopulationBrief): Promise<PopulationBriefRecord>`
   - `getPopulationBrief(id: string): Promise<PopulationBriefRecord | undefined>`
   - `getPopulationBriefsByProject(projectId: string): Promise<PopulationBriefRecord[]>`
3. **New IStorage interface entries** in `server/storage/types.ts`

### Rate Limiting

Max 5 Phase 1 (research) requests per project per hour. Phase 2 (synthesis) is not rate-limited since it's cheap and reuses existing briefs. Enforced via an in-memory counter keyed by `projectId`, reset hourly.

### No New Environment Variables

Uses the existing `OPENAI_API_KEY`. The Responses API and `web_search` tool are accessed through the same OpenAI client library.

---

## 10. Edge Cases & Risks

### Technical Risks

| Risk | Mitigation |
|------|------------|
| **Responses API returns unstructured text despite json_schema** | Parse with try-catch; if JSON parsing fails, retry Phase once; if still failing, surface error to user |
| **Web search returns irrelevant results** | Confidence field in population brief; UI surfaces "ungrounded" warning; researcher can add more context and regenerate |
| **Slow generation (>60s total)** | Two-phase progress indicator; Phase 1 timeout at 90s, Phase 2 at 60s; clear error messages |
| **Generated personas fail schema validation** | Validate each persona against `personaCreateSchema` before presenting; exclude invalid personas from results |

### Cost Risks

| Risk | Mitigation |
|------|------------|
| **Expensive Phase 1 re-runs** | Persist population brief; enable Phase 2-only regeneration |
| **Web search token overhead** | Responses API charges for search context tokens; monitor via LLM usage tracking; reasoning tokens tracked in `rawUsage` |
| **Feature abuse** | Per-project hourly rate limit; all generation events tracked in `llmUsageEvents` |

### Data Risks

| Risk | Mitigation |
|------|------------|
| **Stereotypical personas** | Anti-stereotyping prompts; post-generation diversity validation with retry |
| **Hallucinated citations** | Citations are supplementary context only; never auto-save without researcher review |
| **PII in research prompt** | Research prompt describes populations, not individuals; no PII is expected but no enforcement is needed since the prompt is user-authored |
| **Population brief retention** | Briefs are project-scoped and cascade-deleted when the project is deleted |

---

## 11. Future Extensions (Out of Scope for V1)

1. **Persona refinement from simulation results** — after running simulations, analyze which personas produced valuable responses and suggest adjustments
2. **Cross-project persona reuse** — workspace-level persona library with import/adapt flow
3. **Population brief library** — save and browse briefs across projects
4. **Persona clustering** — visualize generated personas on demographic/behavioral axes, identify coverage gaps
5. **Real-time population sizing** — use web data to estimate what percentage of the target population each persona represents

---

## 12. Implementation Sequence

| Phase | Task | Dependencies |
|-------|------|-------------|
| **1** | Define types in `server/persona-generation/types.ts` — PopulationBrief, GenerationConfig, JSON schemas for Responses API | None |
| **2** | Add `barbara_persona_research` and `barbara_persona_generation` to `LLM_USE_CASES` | None |
| **3** | Add `personaResearch` and `personaGeneration` to `BarbaraConfig` with defaults | None |
| **4** | Add `extractOpenAIResponsesUsage` and `makeResponsesUsageExtractor` to `server/llm-usage.ts` | None |
| **5** | Create `population_briefs` table in `shared/schema.ts` + storage methods | None |
| **6** | Implement Phase 1: `server/persona-generation/research.ts` | 1, 2, 3, 4 |
| **7** | Implement Phase 2: `server/persona-generation/synthesis.ts` | 1, 2, 3, 4 |
| **8** | Implement diversity validation: `server/persona-generation/validation.ts` | 1, 7 |
| **9** | Create routes: `server/routes/persona-generation.routes.ts` | 5, 6, 7, 8 |
| **10** | Build `GeneratePersonasDialog` component (all three states) | 9 |
| **11** | Wire up dialog in `PersonaManager.tsx` with Sparkles button | 10 |
| **12** | Rate limiting and error handling polish | 9 |

Phases 1-5 are independent and can be done in parallel. Phases 6-8 can be done in parallel. Phase 9 requires all backend work. Phases 10-12 require working endpoints.

---

## Key Files Referenced

| File | Relevance |
|------|-----------|
| `shared/schema.ts` (lines 467-489) | `personas` table — generation output must match this |
| `shared/schema.ts` (lines 107-134) | `projects` table — source of auto-fill context |
| `shared/types/llm-usage.ts` | `LLM_USE_CASES` enum to extend; `NormalizedTokenUsage` type |
| `server/llm-usage.ts` | `withTrackedLlmCall`, `extractOpenAIChatUsage` (pattern for new Responses extractor), `makeBarbaraUsageExtractor` |
| `server/barbara-orchestrator.ts` (lines 23-100) | `ALLOWED_MODELS`, `BarbaraConfig`, default config |
| `server/barbara-orchestrator.ts` (lines 2990-3068) | `generateTemplateFromProject` — closest existing generation pattern |
| `server/routes/persona.routes.ts` (lines 15-30) | `personaCreateSchema` — validation schema to reuse |
| `server/storage/simulation.ts` | Existing `createPersona` storage method |
| `server/storage/types.ts` | `IStorage` interface to extend |
| `client/src/components/GenerateTemplateDialog.tsx` | UX pattern to follow |
| `client/src/components/simulation/PersonaManager.tsx` | Integration point for generation button |
| `client/src/components/simulation/PersonaCard.tsx` | Card layout to reuse in review state |
| `server/simulation/types.ts` (line 42) | `SIMULATION_LIMITS.MAX_PERSONAS_PER_RUN` = 10 |
