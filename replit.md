# Alvia - Voice-Based AI Interview Platform

## Overview

Alvia is a voice-based AI interview platform for qualitative research at scale. It leverages OpenAI's GPT-4o Real-time API for natural voice conversations, automatically transcribing and analyzing responses. The platform features consent management, PII redaction, cross-interview analysis, and an advanced analytics system providing insights at Collection, Template, and Project levels. It also includes an invitation system for respondent recruitment and a strategic context feature for tailored analytics recommendations, aiming to transform qualitative research through AI-driven efficiency and insight generation.

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Tech Stack
- **Frontend**: React 18 (TypeScript, Wouter, TanStack React Query, Radix UI, Tailwind CSS)
- **Backend**: Express.js with WebSockets
- **Database**: PostgreSQL with Drizzle ORM
- **Authentication**: Replit OpenID Connect via Passport.js
- **Voice Processing**: OpenAI GPT-4o Real-time API (with multi-provider support for future integration with Grok/xAI)
- **Infographic Generation**: Gemini API (`gemini-3-pro-image-preview`)

### Data Model Hierarchy
The system organizes data hierarchically: **Workspace → Project → InterviewTemplate → Collection → InterviewSession → Segment**.

### Key Design Patterns
- **Storage Abstraction**: Centralized database operations via `DatabaseStorage`.
- **Real-time Communication**: WebSocket server for live voice interview sessions.
- **Form Validation**: Zod schemas integrated with react-hook-form.
- **API Pattern**: REST endpoints with authentication middleware.
- **Component Library**: shadcn/ui.
- **Lag-by-one-turn guidance**: Asynchronous AI guidance for next response.
- **Hybrid Barbara Prompt Strategy**: Barbara receives question summaries for older questions and raw transcript only for the current + previous 2 questions (configurable via `RECENT_TRANSCRIPT_QUESTION_WINDOW`). This replaces the previous full-transcript dump approach, reducing prompt size from O(interview_length) to O(current_question_window) per call. `MAX_TRANSCRIPT_IN_MEMORY` set to 50 as a safety cap. Token estimation and actual usage are logged per Barbara call.
- **Multi-Level Analytics System**: Analytics generated at Collection, Template, and Project levels, with AI-powered cross-template synthesis at the Project level.
- **Strategic Context Integration**: Enables tailored analytics recommendations based on user-provided business context.
- **Aggregated Analytics Command Center**: Centralized dashboard for cross-project insights and analytics health.
- **Respondent Invitation System**: Supports single and bulk invitations with tracking.
- **Session Hygiene System**: Automatic cleanup of abandoned sessions using heartbeat, idle, and max age timeouts.
- **Session Detail Page Enhancements**: Provides comprehensive tools for researchers including export, notes, flagging, and navigation.
- **Project-Level Infographics**: Extends infographic generation to the project level, alongside collection-level support.
- **PDF Export for Analytics**: Comprehensive PDF export for project and collection analytics with smart page breaks and consistent styling.
- **Analytics Cascade Refresh**: Streamlined UX for refreshing analytics dependencies (collections, templates, projects) via a single "Refresh All" action.
- **Data Isolation**: Enforced ownership verification across all data hierarchies (User → Workspace → Project → Template → Collection → Session) for secure multi-tenancy.
- **Auto-Generate Template Feature**: AI-powered generation of interview templates from project metadata using GPT-5.
- **Multi-Provider Realtime Voice Support**: Abstracted `RealtimeProvider` interface to support switching between different real-time voice API providers (e.g., OpenAI, Grok). Researchers select the provider at the Collection level during creation; respondents automatically use the collection's configured provider.
- **Demo Project Auto-Seeding**: New users automatically receive a demo project ("Alvia Demo — Your Coffee Ritual") with a pre-configured template and 6 questions on first login. Implemented via `server/demo-seed.ts` called from the auth verification callback.
- **Invite-Only Waitlist System**: Gating mechanism for public launch. Only users with emails in the `invite_list` table can access the platform. Non-invited authenticated users see a waitlist form to submit their information (name, email, consent preferences). Controlled by `INVITE_ONLY_MODE` environment variable (defaults to true; set to "false" to disable gating). Database tables: `invite_list` (invited emails) and `waitlist_entries` (waitlist submissions). To invite users: `INSERT INTO invite_list (email) VALUES ('user@example.com');`
- **Additional Questions Feature**: AI-powered follow-up questions generated by Barbara (AI analyst) after completing template questions. Configurable per collection (0-3 questions, default 1). Includes opt-in consent dialog, loading states during Barbara's analysis, and dedicated AQ navigation UI. WebSocket protocol extended with new message types for AQ flow. Controlled by `ADDITIONAL_QUESTIONS_ENABLED` environment variable (defaults to true; set to "false" to disable). AQ segments stored in session's `additionalQuestions` JSONB field and displayed separately in review page with "AQ" badges.
- **Silent Ambient Calibration**: Automatic microphone calibration when silence monitoring starts. Measures ambient noise during AnalyserNode warmup period (first 2.5s) and computes a dynamic silence detection threshold using formula: `clamp(baseline × 3.0, 0.005, 0.12)`. Includes safeguards for high variance environments, background tab throttling, and fallback to hardcoded threshold (0.01) on failure. Calibration results sent to server for diagnostics. Implementation in `client/src/hooks/use-silence-detection.ts`.
- **Enhanced Transcription Quality Handling**: Environment check triggers on first foreign language hallucination (not 2+). Re-triggering enabled after 5-utterance cooldown when quality issues persist. Implemented via guard reset logic in `server/voice-interview.ts` and reduced cooldown in `server/transcription-quality.ts`.
- **WebSocket Connection Cleanup**: Uses `removeAllListeners()` before `close()` for instant cleanup of orphaned provider/client connections, preventing stale event processing. ConnectionId guards remain as secondary safety net.
- **Session Duration Tracking**: `totalDurationMs` now centrally computed in `finalizeAndPersistMetrics` and persisted to database for data integrity.
- **Dynamic VAD Eagerness Adjustment**: Mid-session adjustment of OpenAI's semantic VAD eagerness. When `shortUtteranceStreak >= 4` with no recent quality issues (foreign language, incoherence, or repeated-word glitches in last 5 utterances), eagerness is reduced from "auto" to "low". Expanded veto ensures VAD only drops when short utterances are the sole signal—not during transcription quality failures. Restored to "auto" after 10 consecutive good utterances (≥3 words, no recent quality issues). Skips short-utterance tracking for yes_no, scale, and numeric question types. Re-applies eagerness setting after provider reconnect. Tracked via `vadEagernessReduced`, `consecutiveGoodUtterances`, and `recentUtteranceQuality` in TranscriptionQualitySignals. Only applies to OpenAI (Grok uses server_vad). Implementation in `server/voice-interview.ts:sendVadEagernessUpdate()` and `server/transcription-quality.ts`.
- **Dual-Perspective End-of-Interview Summary**: Optional feature (controlled per collection via `endOfInterviewSummaryEnabled`, default off) that generates two independent session summaries when an interview completes: (1) **Alvia's summary** — uses the realtime API's audio-informed context via a text-only response with 30s timeout, capturing conversational nuances; (2) **Barbara's analytical summary** — generated asynchronously from text transcripts using `generateSessionSummary()` in `server/barbara-orchestrator.ts`. Both summaries include themes, overall assessment, and objective satisfaction analysis. The feature is triggered via a unified `finalizeInterview()` function that consolidates all 7 completion paths. Manual Barbara summary regeneration available via `POST /api/sessions/:id/generate-summary`. Frontend: collection toggle in create/edit forms, side-by-side summary cards in session-detail Summary tab. Schema: `alviaSummary` and `barbaraSessionSummary` JSONB columns on `interviewSessions`.
- **Cross-Interview Context Injection**: Low-overhead system that provides Barbara (AI analyst) with theme context and question quality insights from prior interviews in the same collection during live steering. A snapshot is built once at session start from `collection.analyticsData` — no hot-path DB queries. Themes are inverted from `relatedQuestions` arrays into a `themesByQuestion` mapping for efficient per-question lookup. Hard caps enforced: 3 themes per question, 2 emergent themes, 120-char cue truncation. Question quality insights extracted from `questionPerformance` with low-signal guardrails: `MIN_RESPONSE_COUNT_FOR_ALERT=2`, `QUALITY_ALERT_THRESHOLD=65`, `MIN_FLAG_COUNT_FOR_ALERT=2`. Only questions with actionable issues (low quality score, brief responses, recurring flags, narrow perspective) are surfaced. Dual-source gating enables context when either themes or quality insights are available (no longer requires themes). Instructions placed in system prompt with bias guardrails (treat as hypotheses, neutral phrasing); data snapshot and quality block conditionally injected into user prompt. AQ-safe: quality lookups skip additional-question indexes. Controlled by project-level `crossInterviewContext` boolean and `crossInterviewThreshold` (minimum completed sessions). Graceful fallback when feature is disabled, threshold unmet, or analytics data missing. Types: `CompactCrossInterviewTheme`, `CompactQuestionQualityInsight`, `CompactFlagCount`, `CrossInterviewRuntimeContext` in `server/voice-interview.ts`. Builder: `buildCrossInterviewRuntimeContext()`. Prompt helpers: `buildCrossInterviewSnapshotBlock()` and `buildQuestionQualityInsightsBlock()` in `server/barbara-orchestrator.ts`.
- **Automatic WebSocket Reconnection System**: Comprehensive client-side reconnection for handling network interruptions during voice interviews. Features: exponential backoff (500ms base, 10s max, ±20% jitter), 6 max attempts, 5s connection timeout watchdog, token-based stale close prevention, attempt-in-flight guard to prevent overlapping connections. Auto-resumes audio capture after successful reconnect if user was listening before disconnect. Server includes `awaitingResume` and `isPaused` flags in connected payload for proper state sync. UI shows "Reconnecting... (Attempt N of 6)" indicator during reconnection. Network online events trigger reconnection if disconnected. Session termination or unmount stops reconnection cleanly. Implementation in `client/src/pages/interview.tsx`.

## External Dependencies

- **PostgreSQL Database**: Primary data store.
- **OpenAI API**: For GPT-4o Real-time voice interviews, GPT-based interview guidance, and analytics processing.
- **Gemini API**: For infographic generation.
- **Replit Authentication**: OpenID Connect for user authentication.
- **xAI Grok API**: For alternative real-time voice processing (requires `XAI_API_KEY` secret).